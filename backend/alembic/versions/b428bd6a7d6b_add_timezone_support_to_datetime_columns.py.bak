"""Add timezone support to datetime columns

Revision ID: b428bd6a7d6b
Revises: 18815335c350
Create Date: 2025-08-06 01:04:12.044807

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'b428bd6a7d6b'
down_revision: Union[str, Sequence[str], None] = '18815335c350'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('idx_images_accessed'), table_name='image_metadata')
    op.drop_index(op.f('idx_images_product'), table_name='image_metadata')
    op.drop_index(op.f('idx_images_status'), table_name='image_metadata')
    op.drop_index(op.f('idx_images_type'), table_name='image_metadata')
    op.drop_table('image_metadata')
    op.drop_index(op.f('idx_videos_product'), table_name='video_metadata')
    op.drop_index(op.f('idx_videos_status'), table_name='video_metadata')
    op.drop_index(op.f('idx_videos_type'), table_name='video_metadata')
    op.drop_table('video_metadata')
    op.alter_column('instance_tasks', 'attached_media_ids',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               nullable=False)
    op.drop_column('instance_tasks', 'execution_plan')
    op.alter_column('instance_tiktok_credentials', 'access_token_expires_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False)
    op.alter_column('instance_tiktok_credentials', 'refresh_token_expires_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False)
    op.alter_column('instance_tiktok_credentials', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False)
    op.alter_column('instance_tiktok_credentials', 'updated_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False)
    op.alter_column('instance_tiktok_credentials', 'last_used_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
    op.drop_constraint(op.f('uq_instance_tiktok_open_id'), 'instance_tiktok_credentials', type_='unique')
    op.create_index('uq_instance_tiktok_open_id', 'instance_tiktok_credentials', ['instance_id', 'tiktok_open_id'], unique=True)
    op.alter_column('market_opportunities', 'status',
               existing_type=sa.VARCHAR(length=50),
               type_=sa.Enum('PENDING', 'REVIEWED', 'APPROVED', 'REJECTED', 'PROMOTED', name='opportunitystatus'),
               existing_nullable=False,
               existing_server_default=sa.text("'pending'::character varying"))
    op.alter_column('market_opportunities', 'discovery_date',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('market_opportunities', 'reviewed_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True)
    op.drop_index(op.f('idx_opportunities_score'), table_name='market_opportunities')
    op.drop_index(op.f('idx_opportunities_status'), table_name='market_opportunities')
    op.drop_index(op.f('idx_product_tasks_created_at'), table_name='product_tasks')
    op.drop_index(op.f('idx_product_tasks_product_id'), table_name='product_tasks')
    op.drop_index(op.f('idx_product_tasks_status'), table_name='product_tasks')
    op.alter_column('research_metrics', 'metrics_data',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True)
    op.alter_column('trend_snapshots', 'metrics',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=False)
    op.alter_column('trend_snapshots', 'geographic_data',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True)
    op.drop_index(op.f('idx_trends_captured'), table_name='trend_snapshots')
    op.drop_index(op.f('idx_trends_processed'), table_name='trend_snapshots')
    op.alter_column('users', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False)
    op.alter_column('users', 'updated_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('users', 'updated_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False)
    op.alter_column('users', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False)
    op.create_index(op.f('idx_trends_processed'), 'trend_snapshots', ['processed'], unique=False)
    op.create_index(op.f('idx_trends_captured'), 'trend_snapshots', [sa.literal_column('captured_at DESC')], unique=False)
    op.alter_column('trend_snapshots', 'geographic_data',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=postgresql.JSON(astext_type=sa.Text()),
               existing_nullable=True)
    op.alter_column('trend_snapshots', 'metrics',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=postgresql.JSON(astext_type=sa.Text()),
               existing_nullable=False)
    op.alter_column('research_metrics', 'metrics_data',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=postgresql.JSON(astext_type=sa.Text()),
               existing_nullable=True)
    op.create_index(op.f('idx_product_tasks_status'), 'product_tasks', ['status'], unique=False)
    op.create_index(op.f('idx_product_tasks_product_id'), 'product_tasks', ['product_id'], unique=False)
    op.create_index(op.f('idx_product_tasks_created_at'), 'product_tasks', ['created_at'], unique=False)
    op.create_index(op.f('idx_opportunities_status'), 'market_opportunities', ['status'], unique=False)
    op.create_index(op.f('idx_opportunities_score'), 'market_opportunities', [sa.literal_column('score DESC')], unique=False)
    op.alter_column('market_opportunities', 'reviewed_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True)
    op.alter_column('market_opportunities', 'discovery_date',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('market_opportunities', 'status',
               existing_type=sa.Enum('PENDING', 'REVIEWED', 'APPROVED', 'REJECTED', 'PROMOTED', name='opportunitystatus'),
               type_=sa.VARCHAR(length=50),
               existing_nullable=False,
               existing_server_default=sa.text("'pending'::character varying"))
    op.drop_index('uq_instance_tiktok_open_id', table_name='instance_tiktok_credentials')
    op.create_unique_constraint(op.f('uq_instance_tiktok_open_id'), 'instance_tiktok_credentials', ['instance_id', 'tiktok_open_id'], postgresql_nulls_not_distinct=False)
    op.alter_column('instance_tiktok_credentials', 'last_used_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
    op.alter_column('instance_tiktok_credentials', 'updated_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False)
    op.alter_column('instance_tiktok_credentials', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False)
    op.alter_column('instance_tiktok_credentials', 'refresh_token_expires_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False)
    op.alter_column('instance_tiktok_credentials', 'access_token_expires_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False)
    op.add_column('instance_tasks', sa.Column('execution_plan', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.alter_column('instance_tasks', 'attached_media_ids',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               nullable=True)
    op.create_table('video_metadata',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False),
    sa.Column('product_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('storage_path', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('public_url', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('streaming_url', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('video_type', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('duration_seconds', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('file_size', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('resolution', sa.VARCHAR(length=20), autoincrement=False, nullable=True),
    sa.Column('codec', sa.VARCHAR(length=50), autoincrement=False, nullable=True),
    sa.Column('processing_status', sa.VARCHAR(length=50), server_default=sa.text("'pending'::character varying"), autoincrement=False, nullable=True),
    sa.Column('thumbnails', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('storage_backend', sa.VARCHAR(length=50), server_default=sa.text("'supabase'::character varying"), autoincrement=False, nullable=True),
    sa.Column('status', sa.VARCHAR(length=50), server_default=sa.text("'active'::character varying"), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.Column('processed_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('last_accessed_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['product_id'], ['products.id'], name=op.f('video_metadata_product_id_fkey'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('video_metadata_pkey'))
    )
    op.create_index(op.f('idx_videos_type'), 'video_metadata', ['video_type'], unique=False)
    op.create_index(op.f('idx_videos_status'), 'video_metadata', ['status'], unique=False)
    op.create_index(op.f('idx_videos_product'), 'video_metadata', ['product_id'], unique=False)
    op.create_table('image_metadata',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False),
    sa.Column('product_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('storage_path', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('public_url', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('cdn_url', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('image_type', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('sub_type', sa.VARCHAR(length=50), autoincrement=False, nullable=True),
    sa.Column('file_size', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('width', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('height', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('format', sa.VARCHAR(length=10), autoincrement=False, nullable=True),
    sa.Column('generation_session_id', sa.VARCHAR(length=255), autoincrement=False, nullable=True),
    sa.Column('evaluation_score', sa.NUMERIC(precision=3, scale=2), autoincrement=False, nullable=True),
    sa.Column('storage_backend', sa.VARCHAR(length=50), server_default=sa.text("'supabase'::character varying"), autoincrement=False, nullable=True),
    sa.Column('status', sa.VARCHAR(length=50), server_default=sa.text("'active'::character varying"), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.Column('last_accessed_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('archived_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['product_id'], ['products.id'], name=op.f('image_metadata_product_id_fkey'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('image_metadata_pkey'))
    )
    op.create_index(op.f('idx_images_type'), 'image_metadata', ['image_type', 'sub_type'], unique=False)
    op.create_index(op.f('idx_images_status'), 'image_metadata', ['status'], unique=False)
    op.create_index(op.f('idx_images_product'), 'image_metadata', ['product_id'], unique=False)
    op.create_index(op.f('idx_images_accessed'), 'image_metadata', ['last_accessed_at'], unique=False)
    # ### end Alembic commands ###
